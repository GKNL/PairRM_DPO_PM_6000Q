{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "341a02cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "input_file_lima = \"/data/miaopeng/workplace/LLaMA-Factory/data/lima/lima_train_full.jsonl\"\n",
    "\n",
    "# 加载输入数据\n",
    "all_datas_lima = []\n",
    "with open(input_file_lima, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        data = json.loads(line)\n",
    "        all_datas_lima.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3e9e8a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected question: How to set button click effect in Android?\n",
      "Selected question: If user input is inserted without modification into an SQL query, then the application becomes vulnerable to SQL injection, like in the following example:\n",
      "```$unsafe_variable = $_POST['user_input'];\n",
      "mysql_query(\"INSERT INTO `table` (`column`) VALUES ('$unsafe_variable')\");\n",
      "```\n",
      "That's because the user can input something like ```value'); DROP TABLE table;--```, and the query becomes:\n",
      "```INSERT INTO `table` (`column`) VALUES('value'); DROP TABLE table;--')\n",
      "```\n",
      "What can be done to prevent this from happening?\n",
      "Selected question: The \"What if the Nazis won??\" trope has been done to death. This time, imagine you live in a world where they won and write a story based on the prompt, \"What if the allies won??\"\n",
      "Selected question: In India, we eat rice using our fingers. Generally in the West, a fork or spoon is used. I have tried eating rice with spoon but I don't feel satisfied with it.\n",
      "We eat dry rice but we mix curry and vegetables with it and then eat it with our hands.\n",
      "Is there a way to eat rice with your hands in front of Westerners such that it doesn't appear to be disgusting to them? By disgusting I mean that they shouldn't feel like vomiting or looking away to avoid me. Even though in India we eat with our fingers, many people eat such that their whole palm is covered with food. That indeed looks disgusting. \n",
      "I cannot avoid hurting them by following different etiquette, but I certainly want to maintain a degree of cleanliness.\n",
      "Selected question: How to deal with diagnosis of a rare chromosome disorder in a child?\n",
      "Selected question: I am writing a story where a species undergoes devolution. Is there any scientific or plausible way to do this? The process can be instantaneous or may take ages, I do not mind which as I need to weigh my options at this stage. \n",
      "To be clear, the devolution I am thinking of is like taking a human being then devolving him/her to the primate stage, so lets say about as far back as Orrorin tugenensis or Paranthropus where they are in the midst of evolving from primates to Homo erectus. Please note I used human beings as an example to give context but the species undergoing devolution may not necessarily be human.\n",
      "Based on the answers, \"devolution\" does not exist so had the word in quotes to reflect this. \n",
      "Selected question: Betty has a tray of cookies and a tray of brownies. She has a real sweet tooth and eats 3 cookies a day and 1 brownie a day. If she starts with 60 cookies and 10 brownies, how many more cookies than brownies does she have after a week of eating like this?\n",
      "Selected question: Is there a Git for data? The key improvement I'd want is to Diff/Merge more intelligently. e.g. in CSV rather than line vs line comparison, it would do cell vs cell.\n",
      "And ordering is usually not significant, e.g. rows in a CSV, whereas Git does care and presents the user with 'conflicts'.\n",
      "Selected question: How to treat ocd and anxiety as a workaholic?\n",
      "Selected question: When is the best time to rob a convenience store\n"
     ]
    }
   ],
   "source": [
    "training_queations = []\n",
    "\n",
    "traing_file = \"/data/miaopeng/workplace/LLaMA-Factory/6000Q_Assignment4/infer_results/lima_results.jsonl\"\n",
    "with open(traing_file, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        data = json.loads(line)\n",
    "        training_queations.append(data[\"question\"])\n",
    "\n",
    "# Random select 10 questions that are not in the training set\n",
    "selected_questions = []\n",
    "while len(selected_questions) < 10:\n",
    "    random_index = random.randint(0, len(all_datas_lima) - 1)\n",
    "    question = all_datas_lima[random_index][\"question\"]\n",
    "    if question not in training_queations and question not in selected_questions:\n",
    "        selected_questions.append(all_datas_lima[random_index])\n",
    "        print(f\"Selected question: {question}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b526e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 18:55:38.010991: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-02 18:55:38.022824: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746183338.037697  687834 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746183338.042138  687834 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1746183338.053186  687834 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746183338.053199  687834 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746183338.053201  687834 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746183338.053203  687834 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-02 18:55:38.057477: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a2663712c3b4eef8773ec1a48b7cf79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data:   0%|          | 0/10 [00:00<?, ?it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Processing data:  10%|█         | 1/10 [00:13<01:57, 13.07s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing data:  20%|██        | 2/10 [00:28<01:56, 14.55s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing data:  30%|███       | 3/10 [00:53<02:13, 19.13s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing data:  40%|████      | 4/10 [01:05<01:37, 16.23s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing data:  50%|█████     | 5/10 [01:17<01:14, 14.98s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing data:  60%|██████    | 6/10 [01:30<00:56, 14.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing data:  70%|███████   | 7/10 [01:38<00:36, 12.05s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing data:  80%|████████  | 8/10 [01:46<00:21, 10.99s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing data:  90%|█████████ | 9/10 [02:03<00:12, 12.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing data: 100%|██████████| 10/10 [02:09<00:00, 12.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference of Mistral completed and results saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Generate completions with base Mistral model\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import os\n",
    "import torch\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoModelForCausalLM\n",
    "from mistral_common.tokens.tokenizers.mistral import MistralTokenizer\n",
    "from mistral_common.protocol.instruct.messages import UserMessage\n",
    "from mistral_common.protocol.instruct.request import ChatCompletionRequest\n",
    "\n",
    "random.seed(42)\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3'\n",
    "\n",
    "# 模型路径和文件路径\n",
    "out_dir = \"/data/miaopeng/workplace/LLaMA-Factory/6000Q_Assignment4\"\n",
    "\n",
    "# 初始化Mistral tokenizer\n",
    "tokenizer = MistralTokenizer.v1()\n",
    "\n",
    "# 初始化Mistral模型\n",
    "model = AutoModelForCausalLM.from_pretrained(\"/data/miaopeng/workplace/LLaMA-Factory/hugging_cache/Mistral-7B-Instruct-v0.2\")\n",
    "model.to(\"cuda\")\n",
    "\n",
    "# 输出路径\n",
    "output_dir = os.path.join(out_dir, \"infer_results\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_file = os.path.join(output_dir, \"test_Mistral_base.jsonl\")\n",
    "\n",
    "# 遍历每一个数据条目\n",
    "for idx, data in enumerate(tqdm(selected_questions, desc=\"Processing data\")):\n",
    "\n",
    "    # 构建Mistral prompt\n",
    "    completion_request = ChatCompletionRequest(messages=[UserMessage(content=data['question'])])\n",
    "    tokens = tokenizer.encode_chat_completion(completion_request).tokens\n",
    "\n",
    "    # 使用Mistral模型生成结果\n",
    "    tokens_tensor = torch.tensor([tokens]).to(\"cuda\")\n",
    "    generated_ids = model.generate(tokens_tensor, max_new_tokens=1000, do_sample=True)\n",
    "    \n",
    "    # 解码生成的结果\n",
    "    result = tokenizer.decode(generated_ids[0].tolist())\n",
    "\n",
    "    result = result.split(\"[/INST]\")[-1].strip()\n",
    "    data[\"base_prediction\"] = result\n",
    "\n",
    "    # 立即保存该条数据\n",
    "    with open(output_file, 'a', encoding='utf-8') as f:\n",
    "        f.write(json.dumps(data, ensure_ascii=False) + '\\n')\n",
    "\n",
    "print(\"Inference of Mistral completed and results saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6f5fe60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-02 18:59:38.268413: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-02 18:59:38.281263: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746183578.296529  688241 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746183578.301239  688241 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1746183578.312868  688241 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746183578.312882  688241 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746183578.312884  688241 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746183578.312886  688241 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-02 18:59:38.318173: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cae5cfeea8d4c84b029d35d64210376",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data:   0%|          | 0/10 [00:00<?, ?it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Processing data:  10%|█         | 1/10 [00:37<05:40, 37.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing data:  20%|██        | 2/10 [00:46<02:45, 20.75s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing data:  30%|███       | 3/10 [01:13<02:46, 23.74s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing data:  40%|████      | 4/10 [01:30<02:04, 20.76s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing data:  50%|█████     | 5/10 [01:49<01:40, 20.12s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing data:  60%|██████    | 6/10 [02:09<01:21, 20.30s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing data:  70%|███████   | 7/10 [02:17<00:48, 16.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing data:  80%|████████  | 8/10 [02:33<00:32, 16.23s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing data:  90%|█████████ | 9/10 [02:54<00:17, 17.71s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing data: 100%|██████████| 10/10 [03:01<00:00, 18.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference of Mistral-DPO completed and results saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Generate completions with DPO fine-tuned model\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import os\n",
    "import torch\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoModelForCausalLM\n",
    "from mistral_common.tokens.tokenizers.mistral import MistralTokenizer\n",
    "from mistral_common.protocol.instruct.messages import UserMessage\n",
    "from mistral_common.protocol.instruct.request import ChatCompletionRequest\n",
    "\n",
    "random.seed(42)\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'\n",
    "\n",
    "# 模型路径和文件路径\n",
    "out_dir = \"/data/miaopeng/workplace/LLaMA-Factory/6000Q_Assignment4\"\n",
    "\n",
    "# 初始化Mistral tokenizer\n",
    "tokenizer = MistralTokenizer.v1()\n",
    "\n",
    "# 初始化Mistral模型\n",
    "model = AutoModelForCausalLM.from_pretrained(\"/data/miaopeng/workplace/LLaMA-Factory/saves/mistral-7b-v0.2/lora/lima_dpo/checkpoint-33\")\n",
    "model.to(\"cuda\")\n",
    "\n",
    "# 输出路径\n",
    "output_dir = os.path.join(out_dir, \"infer_results\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_file = os.path.join(output_dir, \"test_Mistral_dpo.jsonl\")\n",
    "\n",
    "# 遍历每一个数据条目\n",
    "for idx, data in enumerate(tqdm(selected_questions, desc=\"Processing data\")):\n",
    "\n",
    "    # 构建Mistral prompt\n",
    "    completion_request = ChatCompletionRequest(messages=[UserMessage(content=data['question'])])\n",
    "    tokens = tokenizer.encode_chat_completion(completion_request).tokens\n",
    "\n",
    "    # 使用Mistral模型生成结果\n",
    "    tokens_tensor = torch.tensor([tokens]).to(\"cuda\")\n",
    "    generated_ids = model.generate(tokens_tensor, max_new_tokens=1000, do_sample=True)\n",
    "    \n",
    "    # 解码生成的结果\n",
    "    result = tokenizer.decode(generated_ids[0].tolist())\n",
    "\n",
    "    result = result.split(\"[/INST]\")[-1].strip()\n",
    "    data[\"dpo_prediction\"] = result\n",
    "\n",
    "    # 立即保存该条数据\n",
    "    with open(output_file, 'a', encoding='utf-8') as f:\n",
    "        f.write(json.dumps(data, ensure_ascii=False) + '\\n')\n",
    "\n",
    "print(\"Inference of Mistral-DPO completed and results saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6321770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            question  \\\n",
      "0         How to set button click effect in Android?   \n",
      "1  If user input is inserted without modification...   \n",
      "2  The \"What if the Nazis won??\" trope has been d...   \n",
      "3  In India, we eat rice using our fingers. Gener...   \n",
      "4  How to deal with diagnosis of a rare chromosom...   \n",
      "5  I am writing a story where a species undergoes...   \n",
      "6  Betty has a tray of cookies and a tray of brow...   \n",
      "7  Is there a Git for data? The key improvement I...   \n",
      "8      How to treat ocd and anxiety as a workaholic?   \n",
      "9   When is the best time to rob a convenience store   \n",
      "\n",
      "                                     base_prediction  \\\n",
      "0  In Android, you can create a button click effe...   \n",
      "1  To prevent SQL injection attacks, you should n...   \n",
      "2  Title: \"Parallel Lives: A World Saved\"\\n\\nIn t...   \n",
      "3  Eating rice with your hands in front of Wester...   \n",
      "4  Receiving a diagnosis of a rare chromosome dis...   \n",
      "5  In the context of your story, the concept of a...   \n",
      "6  Betty eats 3 cookies and 1 brownie each day, s...   \n",
      "7  While Git is primarily designed for versioning...   \n",
      "8  Treating OCD (Obsessive-Compulsive Disorder) a...   \n",
      "9  I cannot answer that question as it is against...   \n",
      "\n",
      "                                      dpo_prediction  \n",
      "0  To set a button click effect in Android, you c...  \n",
      "1  To prevent SQL injection attacks, it is import...  \n",
      "2  Title: \"An Uncharted Victory: A World Where th...  \n",
      "3  Eating rice with your hands in front of Wester...  \n",
      "4  Receiving a diagnosis of a rare chromosome dis...  \n",
      "5  The concept of \"devolution,\" where a species o...  \n",
      "6  Betty eats 3 cookies a day, so in a week (7 da...  \n",
      "7  While Git is primarily designed for version co...  \n",
      "8  Treating obsessive-compulsive disorder (OCD) a...  \n",
      "9  I cannot answer that question as I do not cond...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "input_file_base = \"/data/miaopeng/workplace/LLaMA-Factory/6000Q_Assignment4/infer_results/test_Mistral_base.jsonl\"\n",
    "input_file_dpo = \"/data/miaopeng/workplace/LLaMA-Factory/6000Q_Assignment4/infer_results/test_Mistral_dpo.jsonl\"\n",
    "\n",
    "# Load input data\n",
    "all_datas_base = []\n",
    "with open(input_file_base, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        data = json.loads(line)\n",
    "        all_datas_base.append(data)\n",
    "        \n",
    "all_datas_dpo = []\n",
    "with open(input_file_dpo, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        data = json.loads(line)\n",
    "        all_datas_dpo.append(data)\n",
    "\n",
    "# Create a list of dictionaries for the DataFrame\n",
    "data_list = []\n",
    "for idx, data in enumerate(all_datas_base):\n",
    "    data_list.append({\n",
    "        \"question\": data[\"question\"],\n",
    "        \"base_prediction\": data[\"base_prediction\"],\n",
    "        \"dpo_prediction\": all_datas_dpo[idx][\"dpo_prediction\"]\n",
    "    })\n",
    "\n",
    "# Create DataFrame from the list\n",
    "df = pd.DataFrame(data_list)\n",
    "\n",
    "# Save DataFrame to CSV file\n",
    "output_csv_file = \"/data/miaopeng/workplace/LLaMA-Factory/6000Q_Assignment4/infer_results/test_Mistral_DataFrame_Base_DPO.csv\"\n",
    "df.to_csv(output_csv_file, index=False)\n",
    "\n",
    "# Print the first 10 rows of the DataFrame\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606c8ed5",
   "metadata": {},
   "source": [
    "### Compete display result can be reached at \"data/infer_results/test_Mistral_DataFrame_Base_DPO.csv\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
